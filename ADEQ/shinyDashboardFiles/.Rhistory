filter(Index == max(Index)) %>%
distinct(WBID, .keep_all = TRUE) # resolves if multiple indexes are equal in previous step
# Clean up.  Add lat longs and sites to decisions made
j.datagapgis5 <- j.datagapgis4 %>%
left_join(j.normalsite, by = "WBID") %>%
mutate(latitude = ifelse(is.na(latitude), LATITUDE_MEASURE, latitude)) %>%
mutate(longitude = ifelse(is.na(longitude), LONGITUDE_MEASURE, longitude)) %>%
mutate(DatagapSite = ifelse(is.na(DatagapSite), STATION_CD, DatagapSite)) %>%
mutate(WATERBODY_NAME = ifelse(is.na(WATERBODY_NAME), STATION_ALT_NAME, WATERBODY_NAME)) %>%
select(WBID, WATERBODY_NAME, monitoringpriority, latitude, longitude, Flowstatus, Ownership, STATION_ACCESS, googledirections, DriveMinutes, HikeMinutes, Restrictions, DatagapNumbersamples, DatagapSite, DatagapNeeds, SourceIDSites, SourceIDNeeds, PotentialDelist, Champion, Decision, type)
# Combine the itemized datagap list with appendix A for explorer tool
j.dgshort <- j.datagap %>%
filter(exceedorcore == "Yes") %>%
select(WBID, ResultSampleFractionText, CharacteristicName, NewUse, Use, donotsampleseasons, paramcoresampneed)
# Fill in missing acute/chronic using carryforward map (has nothing to do with carry forward but map already exists)
j.dgshort <- j.dgshort %>%
left_join(ZCARRYFORWARDMAP, by = c("CharacteristicName", "Use")) %>%
mutate(NewUse = ifelse(NewUse == 0, cfNewUse, NewUse)) %>%
mutate(NewUse = ifelse(CharacteristicName == "INORGANIC NITROGEN (NITRATE AND NITRITE)", "DWS", NewUse)) %>%
select(-cfResultSampleFraction, -cfNewUse)
# For Dashboard.  Combines appendix a decisions with what is missing and identifies core parameters and if core and seasonal distribution met
j.core <- e.corecomp4 %>%
select(WBID, Use, CharacteristicName, ResultSampleFractionText, COREPARAMETER, COREANDSEASON)
# Load Paste Function that ignores NA's https://stackoverflow.com/questions/13673894/suppress-nas-in-paste
paste3 <- function(...,sep=", ") {
L <- list(...)
L <- lapply(L,function(x) {x[is.na(x)] <- ""; x})
ret <-gsub(paste0("(^",sep,"|",sep,"$)"),"",
gsub(paste0(sep,sep),sep,
do.call(paste,c(L,list(sep=sep)))))
is.na(ret) <- ret==""
ret
}
# Add lake/stream combine miles/acres for summary
YWBHUCREACHSHORT2 <- YWBHUCREACHSHORT %>%
select(WBID, WATER_TYPE)
# Report for Appendix A showing how every assessment decision is made
j.explorer <- j.reporta %>%
select(WBID, WaterbodyName, AcuteChronic, Use, CharacteristicName, ResultSampleFractionText, Binomial, NumberCriteriaMet, NumberCriteriaNotMet, TotalSamples, ImpairmentType, Comment, paramcarryforward, usecarryforward, DecisionParameter, DecisionUse, DecisionWBID, EPACategory, WATERSHED, REACH_DISTANCE, LAKE_ACRES, ORIGIN, TERMINUS) %>%
full_join(j.dgshort, by = c("WBID", "ResultSampleFractionText", "CharacteristicName", "AcuteChronic" = "NewUse", "Use")) %>%
# fix wb
group_by(WBID) %>%
arrange(WBID, DecisionWBID) %>%
fill(WaterbodyName, DecisionWBID, EPACategory, .direction = "down") %>%
# fix use.  No need to fix parameter just leave na as these don't roll up.  A na is an na.
ungroup() %>%
group_by(WBID, Use) %>%
arrange(WBID, Use, DecisionUse) %>%
fill(DecisionUse, .direction = "down") %>%
ungroup() %>%
select(-WaterbodyName) %>%
left_join(YWATERBODYNAME, by = "WBID") %>%
rename(WaterbodyName = WATERBODY_NAME) %>%
left_join(j.core, by = c("WBID", "Use", "CharacteristicName", "ResultSampleFractionText")) %>%
arrange(WBID, Use, CharacteristicName) %>%
rename(Season = donotsampleseasons) %>%
mutate(c1 = ifelse(COREANDSEASON == "Yes", "Full Core and Seasonal Distribution Coverage", NA)) %>%
mutate(c2 = ifelse(COREANDSEASON == "No" & COREPARAMETER == "Y", "Insufficient Information - Missing Core Parameter Coverage and/or Seasonal Distribution", NA)) %>%
mutate(Comment = paste3(Comment, c1, c2)) %>%
replace_na(list(Comment = "No comment")) %>%
select(-c1, -c2) %>%
left_join(YWBHUCREACHSHORT2, by = "WBID") %>%
rename(SampleNeed = paramcoresampneed, WaterType = WATER_TYPE) %>%
select(WBID, WaterbodyName, WaterType, everything())
write.csv(j.explorer, "Appendix A - 2022 Assessment Decisions.csv", row.names = FALSE)
# Export for RTA Dashboard
write.csv(j.explorer, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZAPPA-DECISIONS.csv", row.names = FALSE)
write.csv(j.datagapgis5, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZDATAGAP.csv", row.names = FALSE)
# Meghan's volunteer metric.  Captures basically datagap5 with a date field filtered for just volunteers
j.voldatagap <- j.orggather %>%
ungroup() %>%
select(WBID, CharacteristicName, ResultSampleFractionText, Use, provassess, Volunteer, Total, Org, Orgcode) %>%
filter(Org == "Volunteer") %>%
group_by(provassess) %>%
summarise(sum = sum(Total)) %>%
spread(provassess, sum) %>%
mutate(paramdecision = `Meeting Criteria` + `Not Meeting Criteria`) %>%
mutate(date = Sys.Date())
j.voldecisions <- read_csv("J:/WQD/Surface Water Section/TMDL/Volunteer and Citizen Science/AWW LEAN/Metrics/R Volunteer Assessment Decisions/voldecisions.csv",
col_types = cols(
date = col_date(format = "%Y-%m-%d"),
`Insufficient Information` = col_double(),
`Meeting Criteria` = col_double(),
`Not Meeting Criteria` = col_double(),
paramdecision = col_double(),
`Not Assessed` = col_double()))
j.voldecisions <- bind_rows(j.voldatagap, j.voldecisions)
write.csv(j.voldecisions, "J:/WQD/Surface Water Section/TMDL/Volunteer and Citizen Science/AWW LEAN/Metrics/R Volunteer Assessment Decisions/voldecisions.csv", row.names = FALSE)
# Filter for just assigned sites
j.datagapassign <- j.datagapgis5 %>%
filter(type == "Assigned") %>%
select(WBID, WATERBODY_NAME, Champion, monitoringpriority, DatagapNumbersamples, DatagapSite, DatagapNeeds, SourceIDSites, SourceIDNeeds, PotentialDelist)
# Assigned joined to assessment report for metrics
j.assign <- j.datagapassign %>%
filter(!is.na(monitoringpriority)) %>%
left_join(j.reporta, by = "WBID")
# Record report date for dashboard
reportdate <- as.Date(format(Sys.Date(), "%Y-%m-%d"))
write.csv(reportdate, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZREPORTDATE.csv", row.names = FALSE)
# Percent Assessed Metric
# Stream Universe is from perennial and intermittent streams in T:\data\adeq\water\hydrology\NHDStreams\Flow_Regimes.gdb.  Add P or I to definition query for flow.
# Lake Universe is from T:\data\adeq\water\Assessments\Appendix B waters.gdb
load(file = "inputs/ZUNIVERSE.RData")
j.universe <- nrow(ZUNIVERSE)
# Calculate percent assessed for waterbodies.  Assessed means either a attaining, inconclusive or impaired decision
j.percentassessed <- j.wbid %>%
filter(WBIDAssess %in% c("Attaining", "Inconclusive", "Impaired")) %>%
summarise(CountAssessed = sum(WBID)) %>%
mutate(PercentAssessed = (CountAssessed / j.universe) *100) %>%
mutate(Date = Sys.Date()) %>%
mutate(Type = "Actual")
# Open previous data and append to the current decision
j.percentassessedfile <- read_csv("metrics/percentassessed.csv",
col_types = cols(
Date = col_date(format = "%Y-%m-%d"),
CountAssessed = col_double(),
PercentAssessed = col_double(),
Type = col_character()))
j.percentassessedfile <- bind_rows(j.percentassessed, j.percentassessedfile)
write.csv(j.percentassessedfile, "metrics/percentassessed.csv", row.names = FALSE)
#  Aggregate to monthly
j.paagg <- j.percentassessedfile %>%
group_by(Type, aggdate = floor_date(Date, "1 week")) %>%
summarize(aggpercentassessed = max(PercentAssessed)) %>%
filter(aggdate >= "2020-07-01")
# Make Monthly graph with goal = 26 + current level which is 374 = 400.  26 is used because 29 datagap samples in FY21 and expected that 25 can be visited
j.pagoal <- setNames(data.frame(c(40.0, 42.7), as.Date(c("2020-07-01", "2021-06-30")), c("Goal", "Goal")), c("aggpercentassessed", "aggdate", "Type"))
# Combine actual with goal.
j.pacomb <- bind_rows(j.paagg, j.pagoal)
# Graph
j.pacomb %>%
ggplot(aes(x = aggdate, y = aggpercentassessed, color = Type)) +
geom_line(size = 1.5) +
geom_point(size = 1.5) +
scale_x_date(date_breaks = "1 week") +
scale_linetype_manual(values = c("solid", "dashed")) +
scale_color_manual(values = c("#5c896c", "grey")) +
labs(title = "Percent of Important Waterbodies Assessed (LAG)", x = "", y = "% Assessed", caption = "Pulled Monthly by Jason Jones. SOP/Path = J:/WQD/Surface Water Section/Monitoring Unit/LEAN/RMetrics/percentassessed") +
theme_light() +
theme(axis.text.x = element_text(angle = -90, hjust = 0), legend.position = "bottom", legend.title = element_blank(),
plot.caption = element_text(color = "grey"))
ggsave("percentassessed.jpeg", width = 8, height = 5, units = "in", dpi = 300)
# Number of Decisions
# Decision means making a attaining or impaired decision at the waterbody level
j.decisions <- i.wbid %>%
filter(provassess %in% c(1, 3)) %>%
ungroup() %>%
summarise(CountDecision = n()) %>%
mutate(Date = Sys.Date()) %>%
mutate(Type = "Actual")
# Open previous data and append to the current decision
j.decisionsfile <- read_csv("metrics/decisions.csv",
col_types = cols(
Date = col_date(format = "%Y-%m-%d"),
CountDecision = col_double(),
Type = col_character()))
j.decisionsfile <- bind_rows(j.decisions, j.decisionsfile)
write.csv(j.decisionsfile, "metrics/decisions.csv", row.names = FALSE)
#  Aggregate to monthly
j.decagg <- j.decisionsfile %>%
group_by(Type, aggdate = floor_date(Date, "1 week")) %>%
summarize(aggdecision = max(CountDecision)) %>%
filter(aggdate >= "2020-07-01")
# Make Monthly graph with goal = 26 + current level which is 374 = 400.  26 is used because 29 datagap samples in FY21 and expected that 25 can be visited
j.decdf <- setNames(data.frame(c(192, 222), as.Date(c("2020-07-01", "2021-06-30"))), c("aggdecision", "aggdate"))
j.decdf <- mutate(j.decdf, Type = "Goal")
# Combine actual with goal.
j.deccomb <- bind_rows(j.decagg, j.decdf)
# Graph
j.deccomb %>%
ggplot(aes(x = aggdate, y = aggdecision, color = Type)) +
geom_line(size = 1.5) +
geom_point(size = 1.5) +
scale_x_date(date_breaks = "1 week") +
scale_linetype_manual(values = c("solid", "dashed")) +
scale_color_manual(values = c("#5c896c", "grey")) +
labs(title = "Number of Decisions Made by Waterbody (LAG)", x = "", y = "Count of Decisions", caption = "Pulled Monthly by Jason Jones. SOP/Path = J:/WQD/Surface Water Section/Monitoring Unit/LEAN/RMetrics/decisions") +
theme_light() +
theme(axis.text.x = element_text(angle = -90, hjust = 0), legend.position = "bottom", legend.title = element_blank(),
plot.caption = element_text(color = "grey"))
ggsave("decisions.jpeg", width = 8, height = 5, units = "in", dpi = 300)
#### K - QUALITY ASSURANCE ####
# How many parameter impairments in most recent parameter delist graph?
ZQAPARAM <- read_csv("inputs/ZQAPARAM.csv",
col_types = cols(
WBID = col_character(),
NAME = col_character(),
CharacteristicName = col_character(),
Date = col_date(format = "%m/%d/%Y"),
Action = col_character(),
Stage = col_character(),
Comment = col_character(),
Current = col_character()))
# As on 7/31/20 ELT wants draft WOTUS tracked as the key performance indicator.
# The draft WOTUS metric takes over the old parameter delist graph and WQDB field.
# The ZQAPARAM is now the 'goto' document for provisional history.
# Pulls just the most recent decision at the parameter level
ZQAPARAM <- ZQAPARAM %>%
group_by(WBID, CharacteristicName) %>%
arrange(WBID, CharacteristicName, desc(Date)) %>%
distinct(WBID, CharacteristicName, .keep_all = TRUE) %>%
filter(Action == "Impaired")
# How many parameter impairments are identified by the tool?
k.param <- i.param %>%
filter(provassess == 3)
# Identify differences...both should be 0
# In human but not on delist graph
k.param.a <- k.param %>%
anti_join(ZQAPARAM, by = c("WBID", "CharacteristicName"))
# In delist graph but not human
k.param.b <- ZQAPARAM %>%
anti_join(k.param, by = c("WBID", "CharacteristicName"))
# Agreement between newassess and provassess in human file
k.agreementall <- human %>%
filter(newassess != provassess, is.na(provcomment))
# Logic to show user if QA passed.  Could configure this to actually prompt the user to fix the human file and then rerun a block of code
run = nrow(k.param.a) + nrow(k.param.b)
if(run==0){
print("QA Passed")
}else{
print("Fix human file then rerun from read human to end")
}
end_time <- Sys.time()
end_time - start_time
View(ZQAPARAM)
# Join wotus with current impairments
ZQAPARAM <- read_csv("inputs/ZQAPARAM.csv",
col_types = cols(
WBID = col_character(),
NAME = col_character(),
CharacteristicName = col_character(),
Date = col_date(format = "%m/%d/%Y"),
Action = col_character(),
Stage = col_character(),
Comment = col_character(),
Current = col_character()))
l.provimpairments <- ZQAPARAM %>%
left_join(l.wotus, by = "WBID") %>%
select(WBID, NAME, CharacteristicName, Date, Stage, Action, WOTUSSTATUS, Current, Comment)
# Subset data for WOTUS
# WOTUS (google sheet). WBID level.  https://docs.google.com/spreadsheets/d/1oDB1BX_gENyCjOqErUtwIZvcol4d2gwR8Hz0ZLqIwMs/edit?ts=5f048ba9#gid=964163254
# Inputs.  Credentials will need to be entered at this point
load_data <- function() {
read_sheet("1oDB1BX_gENyCjOqErUtwIZvcol4d2gwR8Hz0ZLqIwMs", "wotusimpaired")
}
l.wotus <- load_data()
# Clean.
l.wotus <- l.wotus %>%
select(WBID, WOTUSSTATUS)
# Itemized wotus impaired parameters
l.wotusparam <- k.param %>%
left_join(l.wotus, by = "WBID") %>%
filter(WOTUSSTATUS == "WOTUS")
# Itemized wotus impaired waterbodies
l.wotuswb <- l.wotusparam %>%
distinct(WBID, WOTUSSTATUS)
# Export dataframes for rta dashboard value boxes
l.wotusparamvb <- nrow(l.wotusparam)
l.wotuswbvb <- nrow(l.wotuswb)
write.csv(l.wotusparamvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZWOTUSPARAMVB.csv", row.names = FALSE)
# Write the provisional numbers to the dashboard as well
l.provparamvb <- nrow(k.param)
l.provwbvb <- nrow(distinct(k.param, WBID))
write.csv(l.provparamvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPROVPARAMVB.csv", row.names = FALSE)
write.csv(l.provwbvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPROVWBVB.csv", row.names = FALSE)
# Join wotus with current impairments
ZQAPARAM <- read_csv("inputs/ZQAPARAM.csv",
col_types = cols(
WBID = col_character(),
NAME = col_character(),
CharacteristicName = col_character(),
Date = col_date(format = "%m/%d/%Y"),
Action = col_character(),
Stage = col_character(),
Comment = col_character(),
Current = col_character()))
l.provimpairments <- ZQAPARAM %>%
left_join(l.wotus, by = "WBID") %>%
select(WBID, NAME, CharacteristicName, Date, Stage, Action, WOTUSSTATUS, Current, Comment)
# Inputs.  Credentials will need to be entered at this point
load_data <- function() {
read_sheet("1oDB1BX_gENyCjOqErUtwIZvcol4d2gwR8Hz0ZLqIwMs", "wotusimpaired")
}
l.wotus <- load_data()
# Clean.
l.wotus <- l.wotus %>%
select(WBID, WOTUSSTATUS)
# Itemized wotus impaired parameters
l.wotusparam <- k.param %>%
left_join(l.wotus, by = "WBID") %>%
filter(WOTUSSTATUS == "WOTUS")
# Itemized wotus impaired waterbodies
l.wotuswb <- l.wotusparam %>%
distinct(WBID, WOTUSSTATUS)
# Export dataframes for rta dashboard value boxes
l.wotusparamvb <- nrow(l.wotusparam)
l.wotuswbvb <- nrow(l.wotuswb)
write.csv(l.wotusparamvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZWOTUSPARAMVB.csv", row.names = FALSE)
# Write the provisional numbers to the dashboard as well
l.provparamvb <- nrow(k.param)
l.provwbvb <- nrow(distinct(k.param, WBID))
write.csv(l.provparamvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPROVPARAMVB.csv", row.names = FALSE)
write.csv(l.provwbvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPROVWBVB.csv", row.names = FALSE)
# Join wotus with current impairments
ZQAPARAM <- read_csv("inputs/ZQAPARAM.csv",
col_types = cols(
WBID = col_character(),
NAME = col_character(),
CharacteristicName = col_character(),
Date = col_date(format = "%m/%d/%Y"),
Action = col_character(),
Stage = col_character(),
Comment = col_character(),
Current = col_character()))
l.provimpairments <- ZQAPARAM %>%
left_join(l.wotus, by = "WBID") %>%
select(WBID, NAME, CharacteristicName, Date, Stage, Action, WOTUSSTATUS, Current, Comment)
#### Charts ####
# Impairment Causes by Parameter
human %>%
filter(provassess == 3) %>%
distinct(WBID, CharacteristicName) %>% # Resolves double counting due to use, fraction
group_by(CharacteristicName) %>%
summarise(Count = n()) %>%
arrange(desc(Count)) %>%
ggplot(aes(x = reorder(CharacteristicName, Count), y = Count)) +
geom_col(alpha = 0.6, fill = "#c00000", color = "#c00000") +
coord_flip() +
labs(y = "Count", x = "") +
scale_y_continuous(breaks = seq(0, 60, 10)) +
theme_light() +
theme(panel.grid.major.y = element_blank(), legend.position = "none")
# Dashboard Export - Impairment Causes
ZPLOTCAUSE <- human %>%
filter(provassess == 3) %>%
distinct(WBID, CharacteristicName) %>% # Resolves double counting due to use, fraction
group_by(CharacteristicName) %>%
summarise(Count = n()) %>%
arrange(desc(Count))
write.csv(ZPLOTCAUSE, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPLOTCAUSE.csv", row.names = FALSE)
# Use Decisions
j.reporta %>%
distinct(WBID, Use, DecisionUse) %>%
group_by(Use, DecisionUse) %>%
summarise(Count = n()) %>%
filter(DecisionUse %in% c("Insufficient information", "Not supporting", "Supporting")) %>%
ggplot(aes(x = reorder(Use, Count), y = Count, fill = DecisionUse, color = DecisionUse)) +
geom_col(alpha = 0.6) +
coord_flip() +
labs(y = "Count", x = "") +
scale_y_continuous(breaks = seq(0, 350, 50), expand = c(0.01, 0)) +
scale_fill_manual(values = c("#ffc000", "#c00000", "#70ad47")) +
scale_color_manual(values = c("#ffc000", "#c00000", "#70ad47")) +
theme_light() +
theme(panel.grid.major.y = element_blank(), legend.position = "bottom", legend.title = element_blank())
# Dashboard Export
ZPLOTUSE <- j.reporta %>%
distinct(WBID, Use, DecisionUse) %>%
group_by(Use, DecisionUse) %>%
summarise(Count = n()) %>%
filter(DecisionUse %in% c("Insufficient information", "Not supporting", "Supporting"))
write.csv(ZPLOTUSE, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPLOTUSE.csv", row.names = FALSE)
# Organization Decisions
c.stddata2 %>%
mutate(Year = year(ActivityStartDate)) %>%
group_by(Year, ActivityConductingOrganizationText) %>%
summarise(Count = n()) %>%
filter(!is.na(ActivityConductingOrganizationText)) %>%
ggplot(aes(x = Year, y = Count, fill = factor(ActivityConductingOrganizationText, levels = c("Volunteer", "USGS", "Other", "Government", "ADEQ")), color = factor(ActivityConductingOrganizationText, levels = c("Volunteer", "USGS", "Other", "Government", "ADEQ")))) +
geom_col(alpha = 0.6) +
labs(y = "Number of Records", x = "") +
scale_fill_manual(values = c("#70ad47", "#ed7d31", "#7030a0", "#c00000", "#4472c4")) +
scale_color_manual(values = c("#70ad47", "#ed7d31", "#7030a0", "#c00000", "#4472c4")) +
scale_y_continuous(breaks = seq(0, 60000, 10000), expand = c(0.01, 0)) +
theme_light() +
theme(panel.grid.major.x = element_blank(),
legend.position = "bottom",
legend.title = element_blank())
# FISH ADVISORY CHECKER
# Open connection object.
conn <- odbcConnect("com", uid="waq_readonly", pwd="waqr3ad")
# Check connection object is open.
odbcGetInfo(conn)
# Query the database and put the results into the data frame
FISH <- sqlQuery(conn,"select STATION_CD, STATION_ALT_NAME, ACTIVITY_END_DATE, FINALID, LAB_QA_FLAGS, SUBSTANCE_NAME, LAB_RESULT, LAB_RESULT_UNIT, DETECTION_LIMIT, DETECTION_LIMIT_UNIT from VW_FISH_QUERY", rows_at_time = 1,believeNRows = FALSE)
#Close connection object.
close(conn)
# Join to c.sites to show WBID
FISH <- FISH %>%
left_join(c.sites, by = c("STATION_CD" = "SiteID"))
# Summarize Fish Results by Waterbody, Fish and Just Mercury...expand to more parameters if needed.
FISH2 <- FISH %>%
filter(SUBSTANCE_NAME == "MERCURY") %>%
mutate(STDDETLIM = ifelse(is.na(DETECTION_LIMIT), 0.012, DETECTION_LIMIT)) %>%
mutate(STDRESULT = ifelse(is.na(LAB_RESULT), STDDETLIM/2, LAB_RESULT)) %>%
select(WBID, STATION_ALT_NAME, ACTIVITY_END_DATE, FINALID, LAB_QA_FLAGS, SUBSTANCE_NAME, LAB_RESULT, LAB_RESULT_UNIT, STDRESULT, STDDETLIM, DETECTION_LIMIT, DETECTION_LIMIT_UNIT)
FISH2$FINALID <- as.character(FISH2$FINALID)
FISH2[grep("APACHE TROUT", FISH2$FINALID), "FINALID"] <- "Apache Trout"
FISH2 %>%
ungroup() %>%
group_by(FINALID) %>%
mutate(median = median(STDRESULT)) %>%
mutate(lowquantile = quantile(STDRESULT, probs = 0.25, type = 6)) %>%
mutate(count = n()) %>%
filter(count >= 10) %>%
ggplot(aes(x=reorder(FINALID, median, na.rm = TRUE), y = STDRESULT)) +
geom_boxplot() +
geom_jitter(alpha = 0.1) +
geom_hline(aes(yintercept = 0.3), col = "red") + #adds a red line for the standard
labs(y = "Mercury in Fish Tissue (mg/kg)", x = "", title = "Mercury in Arizona Fish by Species. Red Line = 0.3 mg/kg Standard.") +
scale_y_continuous(breaks = seq(0, 4, 0.25), expand = c(0.01, 0)) +
# facet_wrap(. ~ CurrentAdvisory)+
coord_flip() +
theme(plot.title = element_text(hjust = 0.5))
ggsave("fish.tiff", width = 17, height = 11, units = "in", dpi = 300)
# Do the advisory based on current criteria.  Need 5 or more fish.  Red = Do not eat, Orange = Limit Consumption, Green is Unlimited Consumption, Yellow is Inconclusive
FISHAdvisory <- FISH2 %>%
group_by(WBID, FINALID) %>%
summarise(count = n(), lastdate = max(ACTIVITY_END_DATE), max = max(STDRESULT), mean = mean(STDRESULT), sd = sd(STDRESULT), meanminussd = mean(STDRESULT)-sd(STDRESULT), meanplussd = mean(STDRESULT)+sd(STDRESULT)) %>%
left_join(YWATERBODYNAME, by = "WBID") %>%
rename(Species = FINALID) %>%
mutate(automatedadvisory = ifelse(max > 2, "Red",
ifelse(count >= 5 & mean >= 0.75, "Red",
ifelse(count >= 5 & mean - sd > 0.3, "Orange",
ifelse(count >= 5 & mean + sd < 0.3, "Green", "Yellow")))))
# Load Existing Fish Advisories
ZFISHADVISORIES <- read_csv("inputs/ZFISHADVISORIES.csv",
col_types = cols(Advice = col_character(),
Color = col_character(), `Date Issued` = col_date(format = "%m/%d/%Y"),
Parameter = col_character(), Species = col_character(),
WBID = col_character(), `Waterbody Name` = col_character()))
# Any Differences?
FISHDifferences <- FISHAdvisory %>%
full_join(ZFISHADVISORIES, by = c("WBID", "Species"))
# # Output to Fish Folder
write.csv(FISHDifferences, paste0("J:/WQD/Surface Water Section/Monitoring Unit/Fish/Automated Fish Advisories R/FishAdvisories",Sys.Date(),".csv"))
write.csv(FISH2, "J:/WQD/Surface Water Section/Monitoring Unit/Fish/Automated Fish Advisories R/Fishdata.csv")
#### L - Extras ####
# Subset data for WOTUS
# WOTUS (google sheet). WBID level.  https://docs.google.com/spreadsheets/d/1oDB1BX_gENyCjOqErUtwIZvcol4d2gwR8Hz0ZLqIwMs/edit?ts=5f048ba9#gid=964163254
# Inputs.  Credentials will need to be entered at this point
load_data <- function() {
read_sheet("1oDB1BX_gENyCjOqErUtwIZvcol4d2gwR8Hz0ZLqIwMs", "wotusimpaired")
}
l.wotus <- load_data()
# Clean.
l.wotus <- l.wotus %>%
select(WBID, WOTUSSTATUS)
# Itemized wotus impaired parameters
l.wotusparam <- k.param %>%
left_join(l.wotus, by = "WBID") %>%
filter(WOTUSSTATUS == "WOTUS")
# Itemized wotus impaired waterbodies
l.wotuswb <- l.wotusparam %>%
distinct(WBID, WOTUSSTATUS)
# Export dataframes for rta dashboard value boxes
l.wotusparamvb <- nrow(l.wotusparam)
l.wotuswbvb <- nrow(l.wotuswb)
write.csv(l.wotusparamvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZWOTUSPARAMVB.csv", row.names = FALSE)
# Write the provisional numbers to the dashboard as well
l.provparamvb <- nrow(k.param)
l.provwbvb <- nrow(distinct(k.param, WBID))
write.csv(l.provparamvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPROVPARAMVB.csv", row.names = FALSE)
write.csv(l.provwbvb, "C:/Users/65942/Desktop/Assessment Dashboard/inputs/ZPROVWBVB.csv", row.names = FALSE)
# Join wotus with current impairments
ZQAPARAM <- read_csv("inputs/ZQAPARAM.csv",
col_types = cols(
WBID = col_character(),
NAME = col_character(),
CharacteristicName = col_character(),
Date = col_date(format = "%m/%d/%Y"),
Action = col_character(),
Stage = col_character(),
Comment = col_character(),
Current = col_character()))
l.provimpairments <- ZQAPARAM %>%
left_join(l.wotus, by = "WBID") %>%
select(WBID, NAME, CharacteristicName, Date, Stage, Action, WOTUSSTATUS, Current, Comment)
View(l.provimpairments)
# How many parameter impairments in most recent parameter delist graph?
ZQAPARAM <- read_csv("inputs/ZQAPARAM.csv",
col_types = cols(
WBID = col_character(),
NAME = col_character(),
CharacteristicName = col_character(),
Date = col_date(format = "%m/%d/%Y"),
Action = col_character(),
Stage = col_character(),
Comment = col_character(),
Current = col_character()))
setwd("C:/Users/65942/Desktop/Assessment Dashboard")
ZPROVIMPAIRMENTS <- read_csv("inputs/ZPROVIMPAIRMENTS.csv",
col_types = cols(Date = col_date(format = "%Y-%m-%d")))
# Replace NAs. Add field to count impairments.
ZPROVIMPAIRMENTS <- ZPROVIMPAIRMENTS %>%
replace_na(list(Current = "Not")) %>%
replace_na(list(WOTUSSTATUS = "Unknown")) %>%
mutate(Counter = ifelse(Action == "Impaired", -1, 1)) %>%
arrange(Stage, Date)
# Factor selection Pickers for ZPROVIMPAIRMENTS
ZPROVIMPAIRMENTS$Stage <- as.factor(ZPROVIMPAIRMENTS$Stage)
ZPROVIMPAIRMENTS$WOTUSSTATUS <- as.factor(ZPROVIMPAIRMENTS$WOTUSSTATUS)
ZPROVIMPAIRMENTS$Action <- as.factor(ZPROVIMPAIRMENTS$Action)
ZPROVIMPAIRMENTS$Current <- as.factor(ZPROVIMPAIRMENTS$Current)
aa <- ZPROVIMPAIRMENTS %>%
arrange(WBID, Current, desc(Date)) %>%
distinct(WBID,  .keep_all = TRUE)
View(aa)
View(aa)
aa <- ZPROVIMPAIRMENTS %>%
arrange(WBID, desc(Date)) %>%
distinct(WBID,  .keep_all = TRUE)
